{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "unlike-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "consolidated-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"carat\",\t\"cut\",\"color\",\"clarity\",\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]\n",
    "data = pd.read_csv('diamonds.csv', na_values='?',    \n",
    "         header=None,  names = headers) \n",
    "data = data.reset_index(drop=True)\n",
    "data = data.iloc[1:]\n",
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "paperback-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode\n",
    "map_cut = {\"Fair\":1, \"Good\":2, \"Very Good\" : 3, \"Premium\" : 4, \"Ideal\" : 5}\n",
    "map_color = {\"J\": 1,\"I\":2, \"H\":3, \"G\":4, \"F\":5, \"E\":6, \"D\":7}\n",
    "map_clarity = {\"I1\":1, \"SI2\":2, \"SI1\":3, \"VS2\":4, \"VS1\":5, \"VVS2\":6, \"VVS1\":7, \"IF\":8}\n",
    "\n",
    "data[\"map_cut\"] = data.cut.map(map_cut)\n",
    "data[\"map_color\"] = data.color.map(map_color)\n",
    "data[\"map_clarity\"] = data.clarity.map(map_clarity)\n",
    "\n",
    "data = data.drop(data.columns[[1,2,3]], axis=1) \n",
    "data = data.apply(pd.to_numeric) \n",
    "data[\"table\"] = data['table'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "physical-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "guilty-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "def normalize_data(col):\n",
    "    max_val = col.max()\n",
    "    min_val = col.min()\n",
    "    for i in range(len(col)):\n",
    "        col[i] = (col[i]-min_val)/(max_val-min_val)\n",
    "    return col\n",
    "\n",
    "col_to_normalize = [\"carat\",\"depth\",\"table\", \"x\",\"y\", \"z\"]\n",
    "for col in col_to_normalize:\n",
    "    data[col] = normalize_data(data[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "brief-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y data\n",
    "Y = data.price\n",
    "X = data.drop('price', axis=1)\n",
    "\n",
    "#Split test train data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=1)\n",
    "\n",
    "# Changing the index of the records to sequential\n",
    "X_train.index=range(len(X_train))\n",
    "Y_train.index=range(len(X_train))\n",
    "X_test.index=range(len(X_test))\n",
    "Y_test.index=range(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "defensive-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eucledian\n",
    "def eucledianDistNeighbours(X_train,Y_train,X_test,K):\n",
    "    distance=[]\n",
    "    for i in range(len(X_train)):\n",
    "        eDistance=0\n",
    "        for j in range(len(X_train.columns)):   \n",
    "            eDistance+=round(pow((X_train.iloc[i,j]-X_test[j]),2))\n",
    "        eDistance = np.sqrt(eDistance)\n",
    "        distance.append((eDistance,i,Y_train.iloc[i]))\n",
    "        distance=sorted(distance, key=lambda x: x[0])[0:K]\n",
    "    return distance\n",
    "\n",
    "# hamming\n",
    "def hammingDistNeighbours(X_train,Y_train,X_test,K):\n",
    "    distance=[]\n",
    "    for i in range(len(X_train)):\n",
    "        hDistance=0\n",
    "        for j in range(len(X_train.columns)):   \n",
    "            hDistance+=round(np.sqrt(pow((X_train.iloc[i,j]-X_test[j]),2)),2)\n",
    "        distance.append((hDistance,i,Y_train.iloc[i]))\n",
    "        distance=sorted(distance, key=lambda x: x[0])[0:K]\n",
    "    return distance\n",
    "\n",
    "# Manhattan \n",
    "def manhattanDistNeighbours(X_train,Y_train,X_test,K):\n",
    "    distance=[]\n",
    "    for i in range(len(X_train)):\n",
    "        mDistance=0\n",
    "        for j in range(len(X_train.columns)):   \n",
    "            mDistance+=round(abs(X_train.iloc[i,j]-X_test[j]),2)\n",
    "        distance.append((mDistance,i,Y_train.iloc[i]))\n",
    "        distance=sorted(distance, key=lambda x: x[0])[0:K]\n",
    "    return distance\n",
    "\n",
    "# Predict the output of the numeric variables based on K nearest neighbours\n",
    "# Output is the mean of the K nearest neighbours\n",
    "def predict(X_train,Y_train,X_test,K, dist):\n",
    "    neighbours=[]\n",
    "    result=[]\n",
    "    if(dist==\"eucledian\"):\n",
    "        for i in range(len(X_test)):\n",
    "            neighbours.append(eucledianDistNeighbours(X_train,Y_train,X_test.iloc[i,:],K))\n",
    "    elif(dist==\"manhattan\"):\n",
    "        for i in range(len(X_test)):\n",
    "            neighbours.append(manhattanDistNeighbours(X_train,Y_train,X_test.iloc[i,:],K))\n",
    "    elif(dist==\"hamming\"):\n",
    "        for i in range(len(X_test)):\n",
    "            neighbours.append(hammingDistNeighbours(X_train,Y_train,X_test.iloc[i,:],K))\n",
    "    \n",
    "    for i in neighbours:\n",
    "        mean=0\n",
    "        for j in i:\n",
    "            mean+=j[-1]\n",
    "        mean=mean/K\n",
    "        result.append(mean)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "grateful-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from the code: 70.45\n"
     ]
    }
   ],
   "source": [
    "# Final training\n",
    "output=predict(X_train,Y_train,X_test,5, \"eucledian\")\n",
    "\n",
    "print('MAE from the code: {:^0.2f}'.format(mean_absolute_error(Y_test,output) ,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b) Do we need to normalise data? [If so Does it make any difference?]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "individual-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183.0168680750493, 70.45199999999998, 0.9471838167513922]\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different distance measures[Euclidean distance, Manhattan distance, Hamming Distance] to handle categorical attributes.\n",
    "eucledian_output = predict(X_train,Y_train,X_test,5, \"eucledian\")\n",
    "manhattan_output = predict(X_train,Y_train,X_test,5, \"manhattan\")\n",
    "# hamming_output = predict(X_train,Y_train,X_test,5, \"hamming\")\n",
    "\n",
    "def getAllErrors(actual, predicted):\n",
    "    errors = []\n",
    "    errors.append(mean_squared_error(actual, predicted, squared=False))\n",
    "    errors.append(mean_absolute_error(actual, predicted))\n",
    "    errors.append(r2_score(actual, predicted))\n",
    "    return errors\n",
    "\n",
    "\n",
    "eucledianError = getAllErrors(Y_test, eucledian_output)\n",
    "manhattanError = getAllErrors(Y_test, manhattan_output)\n",
    "# hammingError = getAllErrors(Y_test, hamming_output)\n",
    "\n",
    "print (eucledianError)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "final-pixel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Eucledian   Manhattan\n",
      "RMSE      183.016868  183.016868\n",
      "MAE        70.452000   70.452000\n",
      "R2-score    0.947184    0.947184\n"
     ]
    }
   ],
   "source": [
    "headers = [\"Eucledian\", \"Manhattan\"]\n",
    "# headers = [\"Eucledian\", \"Manhattan\", \"hamming\"]\n",
    "index = [\"RMSE\", \"MAE\", \"R2-score\"]\n",
    "hammingError = []\n",
    "list_of_tuples = list(zip(eucledianError, manhattanError))\n",
    "# list_of_tuples = list(zip(eucledianError, manhattanError, hammingError))\n",
    "df = pd.DataFrame(list_of_tuples, columns = headers, index=index)\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-renaissance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
